### UNDERSTANDING CONTAINERIZATION TECHNOLOGY USING DOCKERS ###

1. CONTAINER: A container is a way to package application with all the necessary dependencies and configurations

2. CONTAINER REPOSITORY: A special type of storage for containers eg Docker hub (a public container repository)for docker containers.

* Before now, when developing applications, we had to install all dependencies on the server or OS for it to run on that our local. But with containers, we avoid that stress because the container gives us like "It's own isolated operating system layer, with Linux based image." So this way, we have the application packaged with the proper dependencies in the container. So this way, we use same docker commands.

* You could have different version of the same application running on your local system without any conflict. Since the other runs in the containerized environment.

* Containers help eliminate the need for environmental configuration that needs to be set on the server before an application can run. Except for Docker Runtime to be set onetime on the server.

* NB: Docker is one of the most popular implementation of containers. Other implementations include container d, cri-o, etc.


3. Technically, containers are layers of images, with mostly Linux base image (alpine.3.0) because it is small in size.

4. Install docker following the guide from ubuntu: https://docs.docker.com/engine/install/ubuntu/
	You can confirm the version installed by running:
=> docker --version 		##Ref = img 1		

5. To pull a docker image we use
=> docker pull <image name>
eg: => docker pull postgres 		## This will download the latest version if no version is specified. But if not, we can add the version we want to pull.

=> docker pull <image name>:<version number>
eg:  => docker pull postgres:15.8

6. To see all the available docker images
=> docker images

7. To run a docker image we use the "docker run <image name>:<version> eg
=> docker run -d -e POSTGRES_PASSWORD=password postgres 		## Sometimes we might need to specify some extra stuffs.

8. To get help for docker or docker commands, we use
=> docker --help		## for docker commands info
=> docker <command> --help 	## for specific commands help

9. To see all containers we run
=> docker ps 		### for running containers
=> docker ps -a 	### For both running, stoped and failed containers

*** NOTE: 
Image is the actual package that consist of the application, configuration, dependencies, start script, etc. The image is more like the artifact that is moved from the remote repository (eg docker hub).

Container is when the image is pulled to the local machine and started. So container is a running image on a local server. This create the container environment.

10. OS vs VirtualBox vs Docker.

i. OS has two major layer (a) The OS Kernel - This communicate with the hardware and application. like the middle man to aid communication. (b) The application layer, where applications are. They run on the kernel layer.

ii. Docker virtualizes the application layer of an Operating system. And it uses the kernel on the host OS, as it does not have it own kernel.

iii. Virtual machine or Virtual box virtualizes both the Application and OS kernel of an Operating system. So it uses the Host hardware to boot and not the host OS.

11. Docker Architecture: When we install docker, we actually install a docker engine which consist of 3 major components. 
i. Docker Server: For pulling images and managing images and containers
ii. Docker API: For interacting with the docker server
iii. Docker CLI: to execute docker commands against the server.

12. CONTAINER vs IMAGE
## Container: Is a part of the container runtime. It is basically the running environment for an IMAGE
## Image: This is the packaged non-running container. Just like an artifact.

13. DOCKER BASIC COMMANDS
a. docker pull <image name>	=> to download an image from docker hub
b. docker pull <image name>:<version number>	=> to download a particular image version from docker hub
c. docker images	=> to show the list of all images 
d. docker run <image name> 	=> To run an image as a container in an attached mode. If image don't exist, it will pull and run it.
e. docker run -d <image name> 	=> To run the container in a detached mode (more like background)
f. docker stop <container id>	=> to stop a running container
g. docker start <container id>	=> to start a stopped container
h. docker ps 		=> to see all running containers
i. docker ps -a 	=> to see all running and stopped containers
j. docker run -p<host port>:<container port> <image name>  => to bind a port on the host to that of a container
# eg:   docker run -d -p6001:6746 postgress

k. docker logs <container id> 	=> to get the logs of a container
l. docker logs <container name>	=> to get the logs of the container

#eg: docker logs objective_joliot

m. docker run --name <container name> <image name>	=> This is used to give the container a specific name rather than a random name

n. docker rm <container id>  	=>  To delete a container

o. docker rmi <image id> 	=> To delete an image.

p. docker exec -it <container id> /bin/bash	=> To enter into the docker Interactive environment and carry out some tasks or functions.

######## when done with the docker env you use "exit" to return to your normal terminal.
q. docker exec -it <container name> /bin/bash 	=> This also opens up the docker environment

r. docker start <container name>    => to start a container if you gave it a name

s. docker network ls 	=> to see the default docker networks

t. docker network create <network name>  	=> to create a docker network.

u. docker run --net <network name>	=> to run a container in the specified network

v. docker-compose -f <docker compose file>	up		=> to deploy the containers in a docker compose .yaml file

w. docker-compose -f <docker compose file>	down		=> to stop the containers in a docker compose .yaml file

x. docker build -t <image name> <dockerfile location>

####################
THE DOCKER PROJECT
A demo of a Java Script application (A Node JS Backend) connected tot a Mongo-DB databased container with a Mongo-DB UI called mongoExpress.

1. To start the application, I navigated to the application server.js folder and ran the command:
# 	node server.js

I had to run the following commands to fix the unavailable dependencies and get it well set up.
#   npm install 
#	npm install express 		(as it was missen)
#	npm audit fix				(to fix all issues)
# 	npm fund					(for pakages looking for fundings)

Now running # node server.js again, 	The application is running on port 3000.

2. Go ahead and pull the mongoDb and mongo express images from docker hub.
# docker pull mongo
# docker pull mongo-express

3. DOCKER NETWORK
Docker creates it's isolated docker network, where the containers are running in. Hence if i deploy two containers in the same docker network (eg: mongo and mongo-express), They can talk to each other without localhost or port number.
Then external application like the node js application can connect to everything inside the docker network using localhost and the port number.

So we run the two containers for mongodb and mongo-express in the network following the code below:
# docker network create mongo-network 
# docker run -d -p 27017:27017 -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=password --name mongodb --net mongo-network mongo    
# docker run -d -p 8081:8081 -e ME_CONFIG_MONGODB_ADMINUSERNAME=admin -e ME_CONFIG_MONGODB_ADMINPASSWORD=password --net mongo-network --name mongo-express -e ME_CONFIG_MONGODB_SERVER=mongodb mongo-express   

Or in this format:
############
docker run -d \
> -p 8081:8081 \
> -e ME_CONFIG_MONGODB_ADMINUSERNAME=admin \
> -e ME_CONFIG_MONGODB_ADMINPASSWORD=password \
> --net mongo-network \
> --name mongo-express \
> -e ME_CONFIG_MONGODB_SERVER=mongodb \
> mongo-express
############

4. Connect to the Mongo Express UI.
### To connect, we run:  < localhost:8081 >  on our browser.
NB: Your password could be the default password: pass
5. Connect our NodeJS application to the MongoDB database. 
This is done by using the url for the mongodb: localhost:27017 in the nodeJS server.js file.

5. DOCKER COMPOSE:
Used to run multiple docker container at once and repeaatedly, instead of mannually often. it follows this structure:

version: <version number>		# The version of the docker compose file
Services						# Under this is where we list all the containers
	<container 1 name>
		image: <image name>
		ports:
		  - <host>:<container>
		environment:
		  - <specify all the multiple environment varriables

.
.
.

NB: Docker compose takes care of creating a container network for all the containers in the docker compose file.

To execute the docker compose file, we use:
#	docker-compose -f <docker compose file>	up		## the -f flag represents file
eg:  ## docker-compose -f docker-compose.yaml up


6. DOCKERFILE
This serves as a blueprint for building images. It helps us copy our application codes and artifact in a way that it becomes packaged in an image.
Docker files are saved as dockerfile. This is a text file with no extension.
Note, all the below will apply in the container.
#a. FROM: It starts with the base image we are building our image from. For this project, we built on node image i.e FROM node:13-alpine
#b. ENV: Then we set the environment varriables using ENV then the environment key and value
#c. RUN: Used to run Linux commands that will happen inside the container and not on the host.
#d. COPY: Used to execute on Host for Host to Container. eg COPY <host file/directory> <container location>  => COPY ./fileA /home/docker/file
#e. CMD: This is used to execute an entry point commands. eg: CMD ["node", "server.js"]. It will start the application withe the "node server.js" command.
#f. WORKDIR: Use to set the working directory from which to run all commands inside the container.

######
# docker build -t <image name>:<tag> <dockerfile location>
eg:  =>  docker build -t my-image:1.0 ./docker-project/			=> NB: If you don't give a tag, it will have latest as it tag.

7. DOCKER REGISTRY
Docker registories are used to store docker images. 
Using AWS Elastic Container Registry (Amazon ECR) for our private repository.

a. Login to AWS and locate the Amazon ECR Services
b. Create a private repository. For mine I called it app-image.
c. Configure AWS CLI for the account on your local machine. So you can easily login and push the image to the remote private repository.
d. follow the push command instructions to successfully push and tag your image to the ECR.

Here are samples of my commands. Note, I have different AWS profiles configured on my CLI.

# aws ecr get-login-password --region us-east-1 --profile <profile name> | docker login --username AWS --password-stdin <account id>.dkr.ecr.us-east-1.amazonaws.com

# docker tag app-image:1.0 <account id>.dkr.ecr.us-east-1.amazonaws.com/app-image:1.0

# docker push <account id>.dkr.ecr.us-east-1.amazonaws.com/app-image:1.0


8. DEPLOYING THE APPLICATTION FROM THE ECR
For this case, we would need to use our docker compose file (.yml file) where we specify the following:
i. our application image url:  <account id>.dkr.ecr.us-east-1.amazonaws.com/app-image:1.0
ii. The necessary ports to be opened
iii. All other containers that the Application needs to run successfully eg: Mongo and Mongo-Express

After the docker compose file have been created, you run it using the command:
# docker-compose -f <docker compose file> up



